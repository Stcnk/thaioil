{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PyPDF2 import PdfReader\n",
    "from pdfminer.high_level import extract_text\n",
    "from docx import Document\n",
    "from pptx import Presentation\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 156\u001b[0m\n\u001b[0;32m    153\u001b[0m     df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 156\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 144\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m    142\u001b[0m     root_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m(Satang)ChanikarnNik\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive - STelligence Co., Ltd\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGitHub\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mthaioil\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSample_Doc\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Replace with your root folder path\u001b[39;00m\n\u001b[1;32m--> 144\u001b[0m     file_results \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_files_in_subfolders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;66;03m# Convert the results to a DataFrame\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(file_results)\n",
      "Cell \u001b[1;32mIn[1], line 114\u001b[0m, in \u001b[0;36mprocess_files_in_subfolders\u001b[1;34m(root_folder)\u001b[0m\n\u001b[0;32m    112\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(subdir, file)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 114\u001b[0m     page_count, has_figures, figure_count, figure_pages, has_tables, table_count, table_pages, has_thai_language, thai_language_pages \u001b[38;5;241m=\u001b[39m \u001b[43mcount_pages_and_check_figures_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     file_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPDF\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.docx\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "Cell \u001b[1;32mIn[1], line 13\u001b[0m, in \u001b[0;36mcount_pages_and_check_figures_pdf\u001b[1;34m(pdf_path)\u001b[0m\n\u001b[0;32m     10\u001b[0m reader \u001b[38;5;241m=\u001b[39m PdfReader(pdf_path)\n\u001b[0;32m     11\u001b[0m page_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(reader\u001b[38;5;241m.\u001b[39mpages)\n\u001b[1;32m---> 13\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mextract_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m     14\u001b[0m figure_pages \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     15\u001b[0m figure_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\(Satang)ChanikarnNik\\OneDrive - STelligence Co., Ltd\\Documents\\GitHub\\thaioil\\.venv\\lib\\site-packages\\pdfminer\\high_level.py:176\u001b[0m, in \u001b[0;36mextract_text\u001b[1;34m(pdf_file, password, page_numbers, maxpages, caching, codec, laparams)\u001b[0m\n\u001b[0;32m    167\u001b[0m interpreter \u001b[38;5;241m=\u001b[39m PDFPageInterpreter(rsrcmgr, device)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m PDFPage\u001b[38;5;241m.\u001b[39mget_pages(\n\u001b[0;32m    170\u001b[0m     fp,\n\u001b[0;32m    171\u001b[0m     page_numbers,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    174\u001b[0m     caching\u001b[38;5;241m=\u001b[39mcaching,\n\u001b[0;32m    175\u001b[0m ):\n\u001b[1;32m--> 176\u001b[0m     \u001b[43minterpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output_string\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[1;32mc:\\Users\\(Satang)ChanikarnNik\\OneDrive - STelligence Co., Ltd\\Documents\\GitHub\\thaioil\\.venv\\lib\\site-packages\\pdfminer\\pdfinterp.py:997\u001b[0m, in \u001b[0;36mPDFPageInterpreter.process_page\u001b[1;34m(self, page)\u001b[0m\n\u001b[0;32m    995\u001b[0m     ctm \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39mx0, \u001b[38;5;241m-\u001b[39my0)\n\u001b[0;32m    996\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mbegin_page(page, ctm)\n\u001b[1;32m--> 997\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender_contents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresources\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mend_page(page)\n\u001b[0;32m    999\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\(Satang)ChanikarnNik\\OneDrive - STelligence Co., Ltd\\Documents\\GitHub\\thaioil\\.venv\\lib\\site-packages\\pdfminer\\pdfinterp.py:1016\u001b[0m, in \u001b[0;36mPDFPageInterpreter.render_contents\u001b[1;34m(self, resources, streams, ctm)\u001b[0m\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_resources(resources)\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_state(ctm)\n\u001b[1;32m-> 1016\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlist_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstreams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\(Satang)ChanikarnNik\\OneDrive - STelligence Co., Ltd\\Documents\\GitHub\\thaioil\\.venv\\lib\\site-packages\\pdfminer\\pdfinterp.py:1027\u001b[0m, in \u001b[0;36mPDFPageInterpreter.execute\u001b[1;34m(self, streams)\u001b[0m\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1026\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1027\u001b[0m         (_, obj) \u001b[38;5;241m=\u001b[39m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnextobject\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1028\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m PSEOF:\n\u001b[0;32m   1029\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\(Satang)ChanikarnNik\\OneDrive - STelligence Co., Ltd\\Documents\\GitHub\\thaioil\\.venv\\lib\\site-packages\\pdfminer\\psparser.py:661\u001b[0m, in \u001b[0;36mPSStackParser.nextobject\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    659\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 661\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    662\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    663\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def count_pages_and_check_figures_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    page_count = len(reader.pages)\n",
    "    \n",
    "    text = extract_text(pdf_path).lower()\n",
    "    figure_pages = []\n",
    "    figure_count = 0\n",
    "    table_pages = []\n",
    "    table_count = 0\n",
    "    thai_language_pages = []\n",
    "    \n",
    "    for i, page in enumerate(reader.pages):\n",
    "        page_text = page.extract_text().lower()\n",
    "        \n",
    "        # Check for figures\n",
    "        if any(keyword in page_text for keyword in ['figure', 'fig.']):\n",
    "            figure_pages.append(i + 1)\n",
    "            figure_count += 1\n",
    "        \n",
    "        # Check for tables\n",
    "        if 'table' in page_text or re.search(r'\\btable\\b', page_text):\n",
    "            table_pages.append(i + 1)\n",
    "            table_count += 1\n",
    "        \n",
    "        # Check for Thai language\n",
    "        if re.search(r'[\\u0E00-\\u0E7F]', page_text):  # Thai Unicode range\n",
    "            thai_language_pages.append(i + 1)\n",
    "    \n",
    "    has_figures = figure_count > 0\n",
    "    has_tables = table_count > 0\n",
    "    has_thai_language = len(thai_language_pages) > 0\n",
    "    \n",
    "    return page_count, has_figures, figure_count, figure_pages, has_tables, table_count, table_pages, has_thai_language, thai_language_pages\n",
    "\n",
    "def count_pages_and_check_figures_docx(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    page_count = len(doc.element.xpath('//w:sectPr'))\n",
    "    \n",
    "    figure_count = 0\n",
    "    table_count = 0\n",
    "    figure_pages = []\n",
    "    table_pages = []\n",
    "    thai_language_pages = []\n",
    "    \n",
    "    for i, p in enumerate(doc.paragraphs):\n",
    "        # Check for figures\n",
    "        if 'figure' in p.text.lower() or 'fig.' in p.text.lower():\n",
    "            figure_pages.append(i + 1)\n",
    "            figure_count += 1\n",
    "        \n",
    "        # Check for tables\n",
    "        if 'table' in p.text.lower():\n",
    "            table_pages.append(i + 1)\n",
    "            table_count += 1\n",
    "        \n",
    "        # Check for Thai language\n",
    "        if re.search(r'[\\u0E00-\\u0E7F]', p.text):\n",
    "            thai_language_pages.append(i + 1)\n",
    "    \n",
    "    has_figures = figure_count > 0\n",
    "    has_tables = table_count > 0\n",
    "    has_thai_language = len(thai_language_pages) > 0\n",
    "    \n",
    "    return page_count, has_figures, figure_count, figure_pages, has_tables, table_count, table_pages, has_thai_language, thai_language_pages\n",
    "\n",
    "def count_pages_and_check_figures_pptx(pptx_path):\n",
    "    presentation = Presentation(pptx_path)\n",
    "    slide_count = len(presentation.slides)\n",
    "    \n",
    "    figure_count = 0\n",
    "    table_count = 0\n",
    "    figure_pages = []\n",
    "    table_pages = []\n",
    "    thai_language_pages = []\n",
    "    \n",
    "    for i, slide in enumerate(presentation.slides):\n",
    "        slide_text = \"\\n\".join([shape.text for shape in slide.shapes if shape.has_text_frame]).lower()\n",
    "        \n",
    "        # Check for figures\n",
    "        if 'figure' in slide_text or 'fig.' in slide_text:\n",
    "            figure_pages.append(i + 1)\n",
    "            figure_count += 1\n",
    "        \n",
    "        # Check for tables\n",
    "        if 'table' in slide_text or re.search(r'\\btable\\b', slide_text):\n",
    "            table_pages.append(i + 1)\n",
    "            table_count += 1\n",
    "        \n",
    "        # Check for Thai language\n",
    "        if re.search(r'[\\u0E00-\\u0E7F]', slide_text):\n",
    "            thai_language_pages.append(i + 1)\n",
    "    \n",
    "    has_figures = figure_count > 0\n",
    "    has_tables = table_count > 0\n",
    "    has_thai_language = len(thai_language_pages) > 0\n",
    "    \n",
    "    return slide_count, has_figures, figure_count, figure_pages, has_tables, table_count, table_pages, has_thai_language, thai_language_pages\n",
    "\n",
    "def process_files_in_subfolders(root_folder):\n",
    "    results = []\n",
    "\n",
    "    for subdir, _, files in os.walk(root_folder):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            if file.endswith('.pdf'):\n",
    "                page_count, has_figures, figure_count, figure_pages, has_tables, table_count, table_pages, has_thai_language, thai_language_pages = count_pages_and_check_figures_pdf(file_path)\n",
    "                file_type = 'PDF'\n",
    "            elif file.endswith('.docx'):\n",
    "                page_count, has_figures, figure_count, figure_pages, has_tables, table_count, table_pages, has_thai_language, thai_language_pages = count_pages_and_check_figures_docx(file_path)\n",
    "                file_type = 'Word Document'\n",
    "            elif file.endswith('.pptx'):\n",
    "                page_count, has_figures, figure_count, figure_pages, has_tables, table_count, table_pages, has_thai_language, thai_language_pages = count_pages_and_check_figures_pptx(file_path)\n",
    "                file_type = 'PowerPoint'\n",
    "            else:\n",
    "                continue  # Skip non-PDF/Word/PowerPoint files\n",
    "            \n",
    "            results.append({\n",
    "                'file_name': file,\n",
    "                'file_type': file_type,\n",
    "                'page_count': page_count,\n",
    "                'has_figures': has_figures,\n",
    "                'figure_count': figure_count,\n",
    "                'figure_pages': figure_pages,\n",
    "                'has_tables': has_tables,\n",
    "                'table_count': table_count,\n",
    "                'table_pages': table_pages,\n",
    "                'has_thai_language': has_thai_language,\n",
    "                'thai_language_pages': thai_language_pages\n",
    "            })\n",
    "\n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    root_folder = r'C:\\Users\\(Satang)ChanikarnNik\\OneDrive - STelligence Co., Ltd\\Documents\\GitHub\\thaioil\\Sample_Doc'  # Replace with your root folder path\n",
    "\n",
    "    file_results = process_files_in_subfolders(root_folder)\n",
    "    \n",
    "    df = pd.DataFrame(file_results)\n",
    "    \n",
    "    df.to_csv('results.csv', index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pages_and_check_figures_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    page_count = len(reader.pages)\n",
    "    \n",
    "    text = extract_text(pdf_path).lower()\n",
    "    figure_pages = []\n",
    "    figure_count = 0\n",
    "    table_pages = []\n",
    "    table_count = 0\n",
    "    thai_language_pages = []\n",
    "    \n",
    "    for i, page in enumerate(reader.pages):\n",
    "        page_text = page.extract_text().lower()\n",
    "        \n",
    "        # Check for figures\n",
    "        if any(keyword in page_text for keyword in ['figure', 'fig.']):\n",
    "            figure_pages.append(i + 1)\n",
    "            figure_count += 1\n",
    "        \n",
    "        # Check for tables\n",
    "        if 'table' in page_text or re.search(r'\\btable\\b', page_text):\n",
    "            table_pages.append(i + 1)\n",
    "            table_count += 1\n",
    "        \n",
    "        # Check for Thai language\n",
    "        if re.search(r'[\\u0E00-\\u0E7F]', page_text):  # Thai Unicode range\n",
    "            thai_language_pages.append(i + 1)\n",
    "    \n",
    "    has_figures = figure_count > 0\n",
    "    has_tables = table_count > 0\n",
    "    has_thai_language = len(thai_language_pages) > 0\n",
    "    \n",
    "    return page_count, has_figures, figure_count, figure_pages, has_tables, table_count, table_pages, has_thai_language, thai_language_pages\n",
    "\n",
    "def count_pages_and_check_figures_docx(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    page_count = len(doc.element.xpath('//w:sectPr'))\n",
    "    \n",
    "    figure_count = 0\n",
    "    table_count = 0\n",
    "    figure_pages = []\n",
    "    table_pages = []\n",
    "    thai_language_pages = []\n",
    "    \n",
    "    for i, p in enumerate(doc.paragraphs):\n",
    "        # Check for figures\n",
    "        if 'figure' in p.text.lower() or 'fig.' in p.text.lower():\n",
    "            figure_pages.append(i + 1)\n",
    "            figure_count += 1\n",
    "        \n",
    "        # Check for tables\n",
    "        if 'table' in p.text.lower():\n",
    "            table_pages.append(i + 1)\n",
    "            table_count += 1\n",
    "        \n",
    "        # Check for Thai language\n",
    "        if re.search(r'[\\u0E00-\\u0E7F]', p.text):\n",
    "            thai_language_pages.append(i + 1)\n",
    "    \n",
    "    has_figures = figure_count > 0\n",
    "    has_tables = table_count > 0\n",
    "    has_thai_language = len(thai_language_pages) > 0\n",
    "    \n",
    "    return page_count, has_figures, figure_count, figure_pages, has_tables, table_count, table_pages, has_thai_language, thai_language_pages\n",
    "\n",
    "def count_pages_and_check_figures_pptx(pptx_path):\n",
    "    presentation = Presentation(pptx_path)\n",
    "    slide_count = len(presentation.slides)\n",
    "    \n",
    "    figure_count = 0\n",
    "    table_count = 0\n",
    "    figure_pages = []\n",
    "    table_pages = []\n",
    "    thai_language_pages = []\n",
    "    \n",
    "    for i, slide in enumerate(presentation.slides):\n",
    "        slide_text = \"\\n\".join([shape.text for shape in slide.shapes if shape.has_text_frame]).lower()\n",
    "        \n",
    "        # Check for figures\n",
    "        if 'figure' in slide_text or 'fig.' in slide_text:\n",
    "            figure_pages.append(i + 1)\n",
    "            figure_count += 1\n",
    "        \n",
    "        # Check for tables\n",
    "        if 'table' in slide_text or re.search(r'\\btable\\b', slide_text):\n",
    "            table_pages.append(i + 1)\n",
    "            table_count += 1\n",
    "        \n",
    "        # Check for Thai language\n",
    "        if re.search(r'[\\u0E00-\\u0E7F]', slide_text):\n",
    "            thai_language_pages.append(i + 1)\n",
    "    \n",
    "    has_figures = figure_count > 0\n",
    "    has_tables = table_count > 0\n",
    "    has_thai_language = len(thai_language_pages) > 0\n",
    "    \n",
    "    return slide_count, has_figures, figure_count, figure_pages, has_tables, table_count, table_pages, has_thai_language, thai_language_pages\n",
    "\n",
    "def process_files_in_subfolders(root_folder):\n",
    "    results = []\n",
    "\n",
    "    for subdir, _, files in os.walk(root_folder):\n",
    "        subfolder_name = os.path.basename(subdir)  # Get the name of the subfolder\n",
    "        for file in files:\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            if file.endswith('.pdf'):\n",
    "                page_count, has_figures, figure_count, figure_pages, has_tables, table_count, table_pages, has_thai_language, thai_language_pages = count_pages_and_check_figures_pdf(file_path)\n",
    "                file_type = 'PDF'\n",
    "            elif file.endswith('.docx'):\n",
    "                page_count, has_figures, figure_count, figure_pages, has_tables, table_count, table_pages, has_thai_language, thai_language_pages = count_pages_and_check_figures_docx(file_path)\n",
    "                file_type = 'Word Document (docx)'\n",
    "            elif file.endswith('.doc'):\n",
    "                page_count, has_figures, figure_count, figure_pages, has_tables, table_count, table_pages, has_thai_language, thai_language_pages = count_pages_and_check_figures_docx(file_path)\n",
    "                file_type = 'Word Document (doc)'\n",
    "            elif file.endswith('.pptx'):\n",
    "                page_count, has_figures, figure_count, figure_pages, has_tables, table_count, table_pages, has_thai_language, thai_language_pages = count_pages_and_check_figures_pptx(file_path)\n",
    "                file_type = 'PowerPoint'\n",
    "            else:\n",
    "                continue  # Skip non-PDF/Word/PowerPoint files\n",
    "            \n",
    "            results.append({\n",
    "                'subfolder_name': subfolder_name,\n",
    "                'file_name': file,\n",
    "                'file_type': file_type,\n",
    "                'page_count': page_count,\n",
    "                'has_figures': has_figures,\n",
    "                'figure_count': figure_count,\n",
    "                'figure_pages': figure_pages,\n",
    "                'has_tables': has_tables,\n",
    "                'table_count': table_count,\n",
    "                'table_pages': table_pages,\n",
    "                'has_thai_language': has_thai_language,\n",
    "                'thai_language_pages': thai_language_pages\n",
    "            })\n",
    "\n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    folder = 'Sample_Doc'\n",
    "    root_folder = fr'C:\\Users\\(Satang)ChanikarnNik\\OneDrive - STelligence Co., Ltd\\Documents\\GitHub\\thaioil\\{folder}'\n",
    "\n",
    "    file_results = process_files_in_subfolders(root_folder)\n",
    "    \n",
    "    df = pd.DataFrame(file_results)\n",
    "    \n",
    "    \n",
    "    df.to_csv(f'results_{folder}.csv', index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PyPDF2 import PdfReader\n",
    "from pdfminer.high_level import extract_text\n",
    "from docx import Document\n",
    "from pptx import Presentation\n",
    "\n",
    "def count_pages_and_check_figures_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    page_count = len(reader.pages)\n",
    "    \n",
    "    text = extract_text(pdf_path).lower()\n",
    "    figure_pages = []\n",
    "    figure_count = 0\n",
    "    \n",
    "    for i, page in enumerate(reader.pages):\n",
    "        page_text = page.extract_text().lower()\n",
    "        if any(keyword in page_text for keyword in ['figure', 'fig.']):\n",
    "            figure_pages.append(i + 1)\n",
    "            figure_count += 1\n",
    "    \n",
    "    has_figures = figure_count > 0\n",
    "    \n",
    "    return page_count, has_figures, figure_count, figure_pages\n",
    "\n",
    "def count_pages_and_check_figures_docx(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    page_count = len(doc.element.xpath('//w:sectPr'))\n",
    "    figure_count = sum(1 for p in doc.paragraphs if 'figure' in p.text.lower() or 'fig.' in p.text.lower())\n",
    "    has_figures = figure_count > 0\n",
    "    figure_pages = []  # Not applicable in the same way as PDFs, but we can list paragraph numbers\n",
    "    \n",
    "    if has_figures:\n",
    "        for i, p in enumerate(doc.paragraphs):\n",
    "            if 'figure' in p.text.lower() or 'fig.' in p.text.lower():\n",
    "                figure_pages.append(i + 1)\n",
    "    \n",
    "    return page_count, has_figures, figure_count, figure_pages\n",
    "\n",
    "def count_pages_and_check_figures_pptx(pptx_path):\n",
    "    presentation = Presentation(pptx_path)\n",
    "    slide_count = len(presentation.slides)\n",
    "    figure_count = sum(1 for slide in presentation.slides for shape in slide.shapes if shape.has_text_frame and 'figure' in shape.text.lower() or 'fig.' in shape.text.lower())\n",
    "    has_figures = figure_count > 0\n",
    "    figure_pages = []  # Slides with figures\n",
    "    \n",
    "    if has_figures:\n",
    "        for i, slide in enumerate(presentation.slides):\n",
    "            for shape in slide.shapes:\n",
    "                if shape.has_text_frame and ('figure' in shape.text.lower() or 'fig.' in shape.text.lower()):\n",
    "                    figure_pages.append(i + 1)\n",
    "                    break  # Stop after finding the first figure in the slide\n",
    "    \n",
    "    return slide_count, has_figures, figure_count, figure_pages\n",
    "\n",
    "def process_files_in_subfolders(root_folder):\n",
    "    results = []\n",
    "\n",
    "    for subdir, _, files in os.walk(root_folder):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            if file.endswith('.pdf'):\n",
    "                page_count, has_figures, figure_count, figure_pages = count_pages_and_check_figures_pdf(file_path)\n",
    "                file_type = 'PDF'\n",
    "            elif file.endswith('.docx'):\n",
    "                page_count, has_figures, figure_count, figure_pages = count_pages_and_check_figures_docx(file_path)\n",
    "                file_type = 'Word Document'\n",
    "            elif file.endswith('.pptx'):\n",
    "                page_count, has_figures, figure_count, figure_pages = count_pages_and_check_figures_pptx(file_path)\n",
    "                file_type = 'PowerPoint'\n",
    "            else:\n",
    "                continue  # Skip non-PDF/Word/PowerPoint files\n",
    "            \n",
    "            results.append({\n",
    "                'file_name': file,\n",
    "                'file_path': file_path,\n",
    "                'file_type': file_type,\n",
    "                'page_count': page_count,\n",
    "                'has_figures': has_figures,\n",
    "                'figure_count': figure_count,\n",
    "                'figure_pages': figure_pages\n",
    "            })\n",
    "\n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    root_folder = 'your_root_folder_path_here'  # Replace with your root folder path\n",
    "    file_results = process_files_in_subfolders(root_folder)\n",
    "    \n",
    "    # Convert the results to a DataFrame\n",
    "    df = pd.DataFrame(file_results)\n",
    "    \n",
    "    # Display the DataFrame\n",
    "    print(df)\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv('document_analysis_results.csv', index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the document analysis in C:\\Users\\(Satang)ChanikarnNik\\OneDrive - STelligence Co., Ltd\\Documents\\GitHub\\thaioil\\Sample_Doc\n",
      "Processing API 1004_120.40-095.pdf (1/33)...\n",
      "Processing ASME B16.5-2003 Pipe Flanges-Flanged Fittings NPS 12 Through NPS24 MetricInch Standard_120.70-082.pdf (2/33)...\n",
      "Processing ASTM Cetane Method For Rating Diesel Fuels 1963_120.80-006.pdf (3/33)...\n",
      "Processing IEC 112_120.180-158.pdf (4/33)...\n",
      "Processing R1713001-M7008-24-8301-1502-REV0.pdf (5/33)...\n",
      "Processing R1814001-M0020-75-0001-0084-rev1.pdf (6/33)...\n",
      "Processing EN-QTD-45_Integrity Operating Windows Control Plan for U-7500.docx (7/33)...\n",
      "Processing Enqpr04_Integrity Operating Windows Procedure.pdf (8/33)...\n",
      "Processing Enqpr05_Spare Part Management Procedure.pdf (9/33)...\n",
      "Processing MPOF-QWI-750101_START UP SHELL SULFOLANE UNIT (U-7500) WORK INSTRUCTION.docx (10/33)...\n",
      "Processing MPOF-QWI-750201 NORMAL SHUTDOWN SULFOLANE UNIT U7500 WORK INSTRUCTION.docx (11/33)...\n",
      "Processing Mpofqpr03_Product Storage, Handling and Closing Tank Procedure.docx (12/33)...\n",
      "Processing TOES-30-011-rev.1-5.pdf (13/33)...\n",
      "Processing TOSS-10-005-rev4.pdf (14/33)...\n",
      "Processing TOSS-10-010-rev2.pdf (15/33)...\n",
      "Processing TOSS-30-002-rev9.pdf (16/33)...\n",
      "Processing 20210920 Memo Mass balance reconciliation for Parex-Isomar-XRC.pdf (17/33)...\n",
      "Processing Expansion Joint Inspection Strategy Guidline.docx (18/33)...\n",
      "Processing MEMO C-7502 reflux ratio minimization.docx (19/33)...\n",
      "Processing MEMO lower %TOL in C6SC.docx (20/33)...\n",
      "Processing Memo TN 015-22 Long-Term Shutdown of TPX Fuel Oil System.pdf (21/33)...\n",
      "Processing TOP-ENTS-2018-GE-0004_Report HTHA by API 941 Ed 2016_ Area C.pdf (22/33)...\n",
      "Processing TOP-ENTS-2020-RC-002 Guideline of severity level of degradation.pdf (23/33)...\n",
      "Processing TOP-ENTS-2023-GL-0002 Guideline for IOW Control Plan review and update.pdf (24/33)...\n",
      "Processing TOP-ENTS-2023-RC-0001 Guideline for inspection Corrosion Under Insulation (CUI) rev2 15Nov2023.pdf (25/33)...\n",
      "Processing 25190-150-MED-7500-E7505.pdf (26/33)...\n",
      "Processing 25190-150-MPD-7500-P7501.pdf (27/33)...\n",
      "Processing 25190-150-MTD-7500-T7501.pdf (28/33)...\n",
      "Processing EDS Alarm and trip setting.pdf (29/33)...\n",
      "Processing EDS training material.pdf (30/33)...\n",
      "Processing GOM EDS.pdf (31/33)...\n",
      "Processing 20210910 Weekly nuisance trip presentation.pptx (32/33)...\n",
      "Processing 20211015 Weekly nuisance trip presentation.pptx (33/33)...\n",
      "                                            file_name   subfolder_name  \\\n",
      "0                             API 1004_120.40-095.pdf  Code & Standard   \n",
      "1   ASME B16.5-2003 Pipe Flanges-Flanged Fittings ...  Code & Standard   \n",
      "2   ASTM Cetane Method For Rating Diesel Fuels 196...  Code & Standard   \n",
      "3                             IEC 112_120.180-158.pdf  Code & Standard   \n",
      "4                R1713001-M7008-24-8301-1502-REV0.pdf              EDL   \n",
      "5                R1814001-M0020-75-0001-0084-rev1.pdf              EDL   \n",
      "6   EN-QTD-45_Integrity Operating Windows Control ...              ISO   \n",
      "7   Enqpr04_Integrity Operating Windows Procedure.pdf              ISO   \n",
      "8         Enqpr05_Spare Part Management Procedure.pdf              ISO   \n",
      "9   MPOF-QWI-750101_START UP SHELL SULFOLANE UNIT ...              ISO   \n",
      "10  MPOF-QWI-750201 NORMAL SHUTDOWN SULFOLANE UNIT...              ISO   \n",
      "11  Mpofqpr03_Product Storage, Handling and Closin...              ISO   \n",
      "12                            TOES-30-011-rev.1-5.pdf              ISO   \n",
      "13                               TOSS-10-005-rev4.pdf              ISO   \n",
      "14                               TOSS-10-010-rev2.pdf              ISO   \n",
      "15                               TOSS-30-002-rev9.pdf              ISO   \n",
      "16  20210920 Memo Mass balance reconciliation for ...       Memorandum   \n",
      "17  Expansion Joint Inspection Strategy Guidline.docx       Memorandum   \n",
      "18         MEMO C-7502 reflux ratio minimization.docx       Memorandum   \n",
      "19                       MEMO lower %TOL in C6SC.docx       Memorandum   \n",
      "20  Memo TN 015-22 Long-Term Shutdown of TPX Fuel ...       Memorandum   \n",
      "21  TOP-ENTS-2018-GE-0004_Report HTHA by API 941 E...       Memorandum   \n",
      "22  TOP-ENTS-2020-RC-002 Guideline of severity lev...       Memorandum   \n",
      "23  TOP-ENTS-2023-GL-0002 Guideline for IOW Contro...       Memorandum   \n",
      "24  TOP-ENTS-2023-RC-0001 Guideline for inspection...       Memorandum   \n",
      "25                       25190-150-MED-7500-E7505.pdf   Process Manual   \n",
      "26                       25190-150-MPD-7500-P7501.pdf   Process Manual   \n",
      "27                       25190-150-MTD-7500-T7501.pdf   Process Manual   \n",
      "28                     EDS Alarm and trip setting.pdf   Process Manual   \n",
      "29                          EDS training material.pdf   Process Manual   \n",
      "30                                        GOM EDS.pdf   Process Manual   \n",
      "31    20210910 Weekly nuisance trip presentation.pptx              RCM   \n",
      "32    20211015 Weekly nuisance trip presentation.pptx              RCM   \n",
      "\n",
      "        file_type  page_count  has_figures  figure_count  \\\n",
      "0             PDF          30         True            20   \n",
      "1             PDF         233         True            37   \n",
      "2             PDF         139         True            66   \n",
      "3             PDF          11         True             4   \n",
      "4             PDF           6        False             0   \n",
      "5             PDF          13         True             1   \n",
      "6   Word Document           8        False             0   \n",
      "7             PDF          12         True             2   \n",
      "8             PDF          11        False             0   \n",
      "9   Word Document          13        False             0   \n",
      "10  Word Document           8        False             0   \n",
      "11  Word Document           9        False             0   \n",
      "12            PDF           8        False             0   \n",
      "13            PDF           7        False             0   \n",
      "14            PDF           5        False             0   \n",
      "15            PDF          68         True            27   \n",
      "16            PDF          17        False             0   \n",
      "17  Word Document           1         True            23   \n",
      "18  Word Document           1         True            10   \n",
      "19  Word Document           1        False             0   \n",
      "20            PDF           4        False             0   \n",
      "21            PDF          45         True             1   \n",
      "22            PDF          25         True             9   \n",
      "23            PDF          12         True             5   \n",
      "24            PDF          29         True            13   \n",
      "25            PDF           5        False             0   \n",
      "26            PDF          12        False             0   \n",
      "27            PDF           9        False             0   \n",
      "28            PDF           9        False             0   \n",
      "29            PDF         397        False             0   \n",
      "30            PDF         261         True            31   \n",
      "31     PowerPoint          12        False             0   \n",
      "32     PowerPoint          12        False             0   \n",
      "\n",
      "                                         figure_pages  has_tables  \\\n",
      "0   [5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 1...        True   \n",
      "1   [4, 8, 14, 20, 21, 23, 24, 26, 27, 28, 29, 30,...        True   \n",
      "2   [15, 16, 20, 21, 23, 26, 29, 30, 31, 32, 38, 3...        True   \n",
      "3                                      [3, 6, 10, 11]        True   \n",
      "4                                                  []       False   \n",
      "5                                                 [5]        True   \n",
      "6                                                  []        True   \n",
      "7                                              [6, 7]        True   \n",
      "8                                                  []       False   \n",
      "9                                                  []        True   \n",
      "10                                                 []       False   \n",
      "11                                                 []       False   \n",
      "12                                                 []        True   \n",
      "13                                                 []        True   \n",
      "14                                                 []       False   \n",
      "15  [2, 7, 11, 12, 16, 17, 19, 21, 22, 23, 24, 25,...        True   \n",
      "16                                                 []        True   \n",
      "17  [74, 77, 81, 84, 86, 89, 93, 95, 98, 100, 102,...        True   \n",
      "18           [12, 22, 23, 25, 30, 35, 38, 41, 44, 46]       False   \n",
      "19                                                 []       False   \n",
      "20                                                 []       False   \n",
      "21                                                [3]        True   \n",
      "22                 [7, 8, 10, 11, 14, 15, 16, 17, 18]        True   \n",
      "23                                    [3, 4, 5, 7, 9]        True   \n",
      "24  [6, 7, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]        True   \n",
      "25                                                 []       False   \n",
      "26                                                 []       False   \n",
      "27                                                 []       False   \n",
      "28                                                 []       False   \n",
      "29                                                 []        True   \n",
      "30  [9, 10, 11, 12, 13, 16, 18, 37, 39, 91, 92, 97...        True   \n",
      "31                                                 []       False   \n",
      "32                                                 []       False   \n",
      "\n",
      "    table_count                                        table_pages  \\\n",
      "0             6                              [6, 8, 9, 10, 17, 21]   \n",
      "1           200  [4, 7, 8, 11, 12, 13, 14, 16, 17, 18, 19, 20, ...   \n",
      "2            48  [4, 8, 10, 14, 21, 24, 25, 26, 28, 36, 39, 40,...   \n",
      "3             2                                             [7, 8]   \n",
      "4             0                                                 []   \n",
      "5             1                                               [12]   \n",
      "6             1                                               [10]   \n",
      "7             3                                         [8, 9, 10]   \n",
      "8             0                                                 []   \n",
      "9             4                                   [24, 28, 46, 63]   \n",
      "10            0                                                 []   \n",
      "11            0                                                 []   \n",
      "12            3                                          [2, 4, 5]   \n",
      "13            1                                                [7]   \n",
      "14            0                                                 []   \n",
      "15           18  [3, 12, 13, 16, 19, 20, 27, 31, 34, 38, 39, 40...   \n",
      "16            4                                     [1, 7, 10, 12]   \n",
      "17            8              [33, 57, 89, 185, 203, 211, 213, 214]   \n",
      "18            0                                                 []   \n",
      "19            0                                                 []   \n",
      "20            0                                                 []   \n",
      "21            2                                            [4, 24]   \n",
      "22            1                                                [7]   \n",
      "23            3                                         [8, 9, 10]   \n",
      "24            6                            [8, 10, 14, 15, 17, 28]   \n",
      "25            0                                                 []   \n",
      "26            0                                                 []   \n",
      "27            0                                                 []   \n",
      "28            0                                                 []   \n",
      "29           18  [16, 37, 62, 93, 144, 147, 173, 176, 190, 226,...   \n",
      "30           35  [2, 3, 4, 5, 6, 7, 19, 22, 41, 42, 48, 49, 64,...   \n",
      "31            0                                                 []   \n",
      "32            0                                                 []   \n",
      "\n",
      "    has_thai_language                                thai_language_pages  \n",
      "0               False                                                 []  \n",
      "1               False                                                 []  \n",
      "2               False                                                 []  \n",
      "3               False                                                 []  \n",
      "4               False                                                 []  \n",
      "5               False                                                 []  \n",
      "6                True                                                [5]  \n",
      "7                True            [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]  \n",
      "8                True                [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]  \n",
      "9                True  [6, 9, 11, 13, 15, 17, 19, 21, 22, 23, 24, 25,...  \n",
      "10               True  [6, 9, 12, 14, 16, 18, 20, 21, 22, 23, 24, 25,...  \n",
      "11               True  [6, 9, 12, 15, 17, 19, 21, 24, 29, 30, 33, 35,...  \n",
      "12              False                                                 []  \n",
      "13              False                                                 []  \n",
      "14              False                                                 []  \n",
      "15              False                                                 []  \n",
      "16              False                                                 []  \n",
      "17              False                                                 []  \n",
      "18              False                                                 []  \n",
      "19              False                                                 []  \n",
      "20               True                                                [3]  \n",
      "21              False                                                 []  \n",
      "22              False                                                 []  \n",
      "23               True                                                [1]  \n",
      "24              False                                                 []  \n",
      "25              False                                                 []  \n",
      "26              False                                                 []  \n",
      "27              False                                                 []  \n",
      "28              False                                                 []  \n",
      "29              False                                                 []  \n",
      "30              False                                                 []  \n",
      "31              False                                                 []  \n",
      "32              False                                                 []  \n",
      "Analysis complete! Results saved to 'results.csv'.\n"
     ]
    }
   ],
   "source": [
    "def count_pages_and_check_figures_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    page_count = len(reader.pages)\n",
    "    \n",
    "    text = extract_text(pdf_path).lower()\n",
    "    figure_pages = []\n",
    "    figure_count = 0\n",
    "    table_pages = []\n",
    "    table_count = 0\n",
    "    thai_language_pages = []\n",
    "    \n",
    "    for i, page in enumerate(reader.pages):\n",
    "        page_text = page.extract_text().lower()\n",
    "        \n",
    "        # Check for figures\n",
    "        if any(keyword in page_text for keyword in ['figure', 'fig.']):\n",
    "            figure_pages.append(i + 1)\n",
    "            figure_count += 1\n",
    "        \n",
    "        # Check for tables\n",
    "        if 'table' in page_text or re.search(r'\\btable\\b', page_text):\n",
    "            table_pages.append(i + 1)\n",
    "            table_count += 1\n",
    "        \n",
    "        # Check for Thai language\n",
    "        if re.search(r'[\\u0E00-\\u0E7F]', page_text):  # Thai Unicode range\n",
    "            thai_language_pages.append(i + 1)\n",
    "    \n",
    "    has_figures = figure_count > 0\n",
    "    has_tables = table_count > 0\n",
    "    has_thai_language = len(thai_language_pages) > 0\n",
    "    \n",
    "    return page_count, has_figures, figure_count, figure_pages, has_tables, table_count, table_pages, has_thai_language, thai_language_pages\n",
    "\n",
    "def count_pages_and_check_figures_docx(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    page_count = len(doc.element.xpath('//w:sectPr'))\n",
    "    \n",
    "    figure_count = 0\n",
    "    table_count = 0\n",
    "    figure_pages = []\n",
    "    table_pages = []\n",
    "    thai_language_pages = []\n",
    "    \n",
    "    for i, p in enumerate(doc.paragraphs):\n",
    "        # Check for figures\n",
    "        if 'figure' in p.text.lower() or 'fig.' in p.text.lower():\n",
    "            figure_pages.append(i + 1)\n",
    "            figure_count += 1\n",
    "        \n",
    "        # Check for tables\n",
    "        if 'table' in p.text.lower():\n",
    "            table_pages.append(i + 1)\n",
    "            table_count += 1\n",
    "        \n",
    "        # Check for Thai language\n",
    "        if re.search(r'[\\u0E00-\\u0E7F]', p.text):\n",
    "            thai_language_pages.append(i + 1)\n",
    "    \n",
    "    has_figures = figure_count > 0\n",
    "    has_tables = table_count > 0\n",
    "    has_thai_language = len(thai_language_pages) > 0\n",
    "    \n",
    "    return page_count, has_figures, figure_count, figure_pages, has_tables, table_count, table_pages, has_thai_language, thai_language_pages\n",
    "\n",
    "def count_pages_and_check_figures_pptx(pptx_path):\n",
    "    presentation = Presentation(pptx_path)\n",
    "    slide_count = len(presentation.slides)\n",
    "    \n",
    "    figure_count = 0\n",
    "    table_count = 0\n",
    "    figure_pages = []\n",
    "    table_pages = []\n",
    "    thai_language_pages = []\n",
    "    \n",
    "    for i, slide in enumerate(presentation.slides):\n",
    "        slide_text = \"\\n\".join([shape.text for shape in slide.shapes if shape.has_text_frame]).lower()\n",
    "        \n",
    "        # Check for figures\n",
    "        if 'figure' in slide_text or 'fig.' in slide_text:\n",
    "            figure_pages.append(i + 1)\n",
    "            figure_count += 1\n",
    "        \n",
    "        # Check for tables\n",
    "        if 'table' in slide_text or re.search(r'\\btable\\b', slide_text):\n",
    "            table_pages.append(i + 1)\n",
    "            table_count += 1\n",
    "        \n",
    "        # Check for Thai language\n",
    "        if re.search(r'[\\u0E00-\\u0E7F]', slide_text):\n",
    "            thai_language_pages.append(i + 1)\n",
    "    \n",
    "    has_figures = figure_count > 0\n",
    "    has_tables = table_count > 0\n",
    "    has_thai_language = len(thai_language_pages) > 0\n",
    "    \n",
    "    return slide_count, has_figures, figure_count, figure_pages, has_tables, table_count, table_pages, has_thai_language, thai_language_pages\n",
    "\n",
    "def process_files_in_subfolders(root_folder):\n",
    "    results = []\n",
    "    total_files = 0\n",
    "    \n",
    "    # First, count the total number of files to process for progress tracking\n",
    "    for subdir, _, files in os.walk(root_folder):\n",
    "        total_files += len(files)\n",
    "    \n",
    "    processed_files = 0\n",
    "    \n",
    "    for subdir, _, files in os.walk(root_folder):\n",
    "        subfolder_name = os.path.basename(subdir)  # Get the name of the subfolder\n",
    "        for file in files:\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            processed_files += 1\n",
    "            print(f\"Processing {file} ({processed_files}/{total_files})...\")\n",
    "            \n",
    "            if file.endswith('.pdf'):\n",
    "                page_count, has_figures, figure_count, figure_pages, has_tables, table_count, table_pages, has_thai_language, thai_language_pages = count_pages_and_check_figures_pdf(file_path)\n",
    "                file_type = 'PDF'\n",
    "            elif file.endswith('.docx'):\n",
    "                page_count, has_figures, figure_count, figure_pages, has_tables, table_count, table_pages, has_thai_language, thai_language_pages = count_pages_and_check_figures_docx(file_path)\n",
    "                file_type = 'Word Document'\n",
    "            elif file.endswith('.pptx'):\n",
    "                page_count, has_figures, figure_count, figure_pages, has_tables, table_count, table_pages, has_thai_language, thai_language_pages = count_pages_and_check_figures_pptx(file_path)\n",
    "                file_type = 'PowerPoint'\n",
    "            else:\n",
    "                print(f\"Skipping {file} (Unsupported file type)\")\n",
    "                continue  # Skip non-PDF/Word/PowerPoint files\n",
    "            \n",
    "            results.append({\n",
    "                'file_name': file,\n",
    "                'subfolder_name': subfolder_name,\n",
    "                'file_type': file_type,\n",
    "                'page_count': page_count,\n",
    "                'has_figures': has_figures,\n",
    "                'figure_count': figure_count,\n",
    "                'figure_pages': figure_pages,\n",
    "                'has_tables': has_tables,\n",
    "                'table_count': table_count,\n",
    "                'table_pages': table_pages,\n",
    "                'has_thai_language': has_thai_language,\n",
    "                'thai_language_pages': thai_language_pages\n",
    "            })\n",
    "\n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    root_folder = r'C:\\Users\\(Satang)ChanikarnNik\\OneDrive - STelligence Co., Ltd\\Documents\\GitHub\\thaioil\\Sample_Doc'  # Replace with your root folder path\n",
    "\n",
    "    print(f\"Starting the document analysis in {root_folder}\")\n",
    "    file_results = process_files_in_subfolders(root_folder)\n",
    "    \n",
    "    # Convert the results to a DataFrame\n",
    "    df = pd.DataFrame(file_results)\n",
    "    \n",
    "    # Display the DataFrame\n",
    "    print(df)\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv('results_analysis.csv', index=False)\n",
    "    print(f\"Analysis complete! Results saved to 'results.csv'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
